{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO4NaJLfoe3x2dTlPgavRPj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x-jp627jotqe"},"outputs":[],"source":["! pip install --upgrade codetiming numpy pandas census us mechanicalsoup geopandas pandas_bokeh torch\n","get_ipython().kernel.do_shutdown(True)"]},{"cell_type":"code","source":["mount_path = '/content/drive'\n","repo_path = f'{mount_path}/MyDrive/gerrymandering/2022-10/voting_predictor'\n","from google.colab import drive\n","drive.mount(mount_path)\n","%cd {repo_path}\n","%load_ext google.colab.data_table\n","%load_ext autoreload\n","%autoreload\n","from model import *\n","%cd {repo_path}\n","%load_ext google.colab.data_table\n","\n","%load_ext autoreload\n","%autoreload\n","from model import *\n","\n","class Feedforward(torch.nn.Module):\n","    def __init__(self, input_size, hidden_size, activation):\n","        super(Feedforward, self).__init__()\n","        assert len(hidden_size) == len(activation), 'hidden_size and activation must have same length'\n","        L = []\n","        p = input_size\n","        for q, f in zip(hidden_size, activation):\n","            L.append(torch.nn.Linear(p, q))\n","            L.append(f())\n","            p = q\n","        self.nn = torch.nn.Sequential(*L)\n","        self.rmse_train = []\n","        self.rmse_test  = []\n","\n","    def forward(self, X, W):\n","        self.prop = self.nn(X)\n","        # print(self.prop.shape, W.shape, B.shape)\n","        self.pred = ((self.prop * W) @ B).squeeze()\n","        # print(self.pred.shape)\n","        return self.pred\n","\n","    def get_rmse(self):\n","        self.rmse_train.append(np.sqrt(loss_fcn(self(X_train, W_train), Y_train).item()))\n","        self.rmse_test .append(np.sqrt(loss_fcn(self(X_test , W_test ), Y_test ).item()))\n","        \n","\n","\n","feat = [\n","    # 'aland',\n","    # 'polsby_popper',\n","    'dist_to_border',\n","    # 'white_tot_pop'       , 'hisp_tot_pop'       , 'other_tot_pop',\n","    # 'white_vap_pop'       , 'hisp_vap_pop'       , 'other_vap_pop',\n","    'white_vap_density'   , 'hisp_vap_density'   , 'other_vap_density',\n","    'white_vap_poverty'   , 'hisp_vap_poverty'   , 'other_vap_poverty',\n","    'white_vap_elderly'   , 'hisp_vap_elderly'   , 'other_vap_elderly',\n","    'white_vap_highschool', 'hisp_vap_highschool', 'other_vap_highschool',\n","    'hisp_vap_spanish_at_home_english_well',\n","]\n","targ = ['d', 'r']\n","weig = ['white_vap_pop', 'hisp_vap_pop', 'other_vap_pop']\n","\n","elections = ['2020_general_President', '2016_general_President', '2018_general_USSen', '2020_general_USSen']\n","df = pd.concat([features(*elec.split('_')) for elec in elections])[feat+targ+weig].sample(frac=1)\n","W = df[weig].astype(float)\n","W = W.join(W, lsuffix='_d', rsuffix='_r')\n","Y = df[targ].astype(float)\n","X = df[feat].astype(float)\n","X = (X - X.min()) / (X.max() - X.min())\n","B = torch.FloatTensor([[1,1,1,0,0,0],[0,0,0,1,1,1,]]).T.to(device)\n","for elec in elections:\n","    W_test  = torch.FloatTensor(W.query('election == @elec').values).to(device)\n","    X_test  = torch.FloatTensor(X.query('election == @elec').values).to(device)\n","    Y_test  = torch.FloatTensor(Y.query('election == @elec').values).to(device)\n","    W_train = torch.FloatTensor(W.query('election != @elec').values).to(device)\n","    X_train = torch.FloatTensor(X.query('election != @elec').values).to(device)\n","    Y_train = torch.FloatTensor(Y.query('election != @elec').values).to(device)\n","\n","    model = Feedforward(\n","        input_size = X_train.shape[1],\n","        hidden_size = (50, 6),\n","        activation = (torch.nn.ReLU, torch.nn.Sigmoid)\n","    ).to(device)\n","    loss_fcn = torch.nn.MSELoss()\n","    optimizer = torch.optim.Adam(model.parameters())\n","    \n","    steps = 1000\n","    for k in range(steps):\n","        optimizer.zero_grad()  # Clear gradient\n","        loss = loss_fcn(model(X_train, W_train), Y_train) # Compute train loss\n","        loss.backward()  # Backward propagation\n","        optimizer.step()  # Learn\n","        model.rmse_train.append(np.sqrt(loss.item()))\n","        # model.get_rmse()\n","    break\n","model.rmse_train[-10:]\n"],"metadata":{"id":"ifb2XGpbaf7O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682654699,"user_tz":300,"elapsed":4043,"user":{"displayName":"TSU Math","userId":"02445136285393801696"}},"outputId":"10cb1cb3-afae-405b-8394-14635876feea"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/gerrymandering/2022-10/voting_predictor\n","The google.colab.data_table extension is already loaded. To reload it, use:\n","  %reload_ext google.colab.data_table\n","The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","/content/drive/MyDrive/gerrymandering/2022-10/voting_predictor\n","The google.colab.data_table extension is already loaded. To reload it, use:\n","  %reload_ext google.colab.data_table\n","The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]},{"output_type":"execute_result","data":{"text/plain":["[223.69032025324654,\n"," 223.64789919089336,\n"," 223.60555742758274,\n"," 223.5632862720308,\n"," 223.5210333363507,\n"," 223.47881611016288,\n"," 223.4368531459168,\n"," 223.39468995479726,\n"," 223.35281612003462,\n"," 223.31072452414818]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["(model.pred-Y_train)/Y_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":167},"id":"K8MiICpbA7zP","executionInfo":{"status":"error","timestamp":1666682545468,"user_tz":300,"elapsed":5,"user":{"displayName":"TSU Math","userId":"02445136285393801696"}},"outputId":"fa0932aa-829e-4d96-996a-2bbbfff26dd2"},"execution_count":12,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-5c81163ea013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8740) must match the size of tensor b (26249) at non-singleton dimension 0"]}]}]}