{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMCvDrfQkc9gTmiAERlD1of"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x-jp627jotqe"},"outputs":[],"source":["! pip install --upgrade codetiming numpy pandas census us mechanicalsoup geopandas pandas_bokeh torch\n","get_ipython().kernel.do_shutdown(True)"]},{"cell_type":"code","source":["mount_path = '/content/drive'\n","repo_path = f'{mount_path}/MyDrive/gerrymandering/2022-10/voting_predictor'\n","from google.colab import drive\n","drive.mount(mount_path)\n","%cd {repo_path}\n","%load_ext google.colab.data_table\n","%load_ext autoreload\n","%autoreload\n","from model import *\n","%cd {repo_path}\n","%load_ext google.colab.data_table\n","\n","%load_ext autoreload\n","%autoreload\n","from model import *\n","\n","class Feedforward(torch.nn.Module):\n","    def __init__(self, input_size, hidden_size, activation):\n","        super(Feedforward, self).__init__()\n","        assert len(hidden_size) == len(activation), 'hidden_size and activation must have same length'\n","        L = []\n","        p = input_size\n","        for q, f in zip(hidden_size, activation):\n","            L.append(torch.nn.Linear(p, q))\n","            L.append(f())\n","            p = q\n","        self.nn = torch.nn.Sequential(*L)\n","        self.rmse_train = []\n","        self.rmse_test  = []\n","\n","    def forward(self, X, W):\n","        self.prop = self.nn(X)\n","        # print(self.prop.shape, W.shape, B.shape)\n","        self.pred = ((self.prop * W) @ B).squeeze()\n","        # print(self.pred.shape)\n","        return self.pred\n","\n","    def get_rmse(self):\n","        self.rmse_train.append(np.sqrt(loss_fcn(self(X_train, W_train), Y_train).item()))\n","        self.rmse_test .append(np.sqrt(loss_fcn(self(X_test , W_test ), Y_test ).item()))\n","        \n","\n","\n","feat = [\n","    # 'aland',\n","    # 'polsby_popper',\n","    'dist_to_border',\n","    # 'white_tot_pop'       , 'hisp_tot_pop'       , 'other_tot_pop',\n","    # 'white_vap_pop'       , 'hisp_vap_pop'       , 'other_vap_pop',\n","    'white_vap_density'   , 'hisp_vap_density'   , 'other_vap_density',\n","    'white_vap_poverty'   , 'hisp_vap_poverty'   , 'other_vap_poverty',\n","    'white_vap_elderly'   , 'hisp_vap_elderly'   , 'other_vap_elderly',\n","    'white_vap_highschool', 'hisp_vap_highschool', 'other_vap_highschool',\n","    'hisp_vap_spanish_at_home_english_well',\n","]\n","targ = ['d', 'r']\n","weig = ['white_vap_pop', 'hisp_vap_pop', 'other_vap_pop']\n","\n","elections = ['2020_general_President', '2016_general_President', '2018_general_USSen', '2020_general_USSen']\n","df = pd.concat([features(*elec.split('_')) for elec in elections])[feat+targ+weig].sample(frac=1)\n","W = df[weig].astype(float)\n","W = W.join(W, lsuffix='_d', rsuffix='_r')\n","Y = df[targ].astype(float)\n","X = df[feat].astype(float)\n","X = (X - X.min()) / (X.max() - X.min())\n","B = torch.FloatTensor([[1,1,1,0,0,0],[0,0,0,1,1,1,]]).T.to(device)\n","for elec in elections:\n","    W_test  = torch.FloatTensor(W.query('election == @elec').values).to(device)\n","    X_test  = torch.FloatTensor(X.query('election == @elec').values).to(device)\n","    Y_test  = torch.FloatTensor(Y.query('election == @elec').values).to(device)\n","    W_train = torch.FloatTensor(W.query('election != @elec').values).to(device)\n","    X_train = torch.FloatTensor(X.query('election != @elec').values).to(device)\n","    Y_train = torch.FloatTensor(Y.query('election != @elec').values).to(device)\n","\n","    model = Feedforward(\n","        input_size = X_train.shape[1],\n","        hidden_size = (50, 6),\n","        activation = (torch.nn.ReLU, torch.nn.Sigmoid)\n","    ).to(device)\n","    loss_fcn = torch.nn.MSELoss()\n","    optimizer = torch.optim.Adam(model.parameters())\n","    \n","    steps = 2\n","    for k in range(steps):\n","        optimizer.zero_grad()  # Clear gradient\n","        loss = loss_fcn(model(X_train, W_train), Y_train) # Compute train loss\n","        loss.backward()  # Backward propagation\n","        optimizer.step()  # Learn\n","        model.get_rmse()\n","        print(loss)\n","    break\n","model.rmse_test\n"],"metadata":{"id":"ifb2XGpbaf7O"},"execution_count":null,"outputs":[]}]}